{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b11126da",
   "metadata": {},
   "source": [
    "# Removing irrelevant images from webscraping with Yolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cf3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031398c5",
   "metadata": {},
   "source": [
    "## Evaluating Yolov3 model through confusion matrix <br>\n",
    "Yolov3 model was trained for 1000 iterations on Google Colab's GPU, giving us the weights found in \"yolov3_training_final.weights\". We then test the trained model and plot a confusion matrix as shown below.<br><br>\n",
    "<b>Training dataset</b>: <i>yolo_labelled_images_final</i> => <u>100 labelled images (webscraped) containing carton boxes</u><br>\n",
    "<b>Testing dataset</b>: <i>yolo_test_images_final</i> => <u>50 webscraped images with half-half split between relevant (w carton box) and irrelevant images (w/o carton box)</u>; <br>~Note: testing dataset and training dataset do not overlap. i.e. test set images do not contain training set images for fair testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07721157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted results:  [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# testing the model by running it through a test dataset (\"yolo_test_images_final\") \n",
    "\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3_training_final.weights\", \"yolov3_testing.cfg\")\n",
    "\n",
    "# Name custom object\n",
    "classes = [\"carton_box\"]\n",
    "\n",
    "# Images path\n",
    "images_path = glob.glob(r\"C:\\Users\\LeeX\\Desktop\\Proof_Of_Concept\\yolo_test_images_final\\*.jpg\")\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "#1 means got box, 0 means no box\n",
    "#based \n",
    "actual_y = [1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,1,1,1]\n",
    "predicted_y = []\n",
    "\n",
    "# Insert here the path of your images\n",
    "# random.shuffle(images_path)\n",
    "\n",
    "# loop through all the images\n",
    "for img_path in images_path:\n",
    "    # Loading image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, None, fx=0.8, fy=0.8)\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    # creating a 4D blob + preprocessing (normalising images by rescaling 1/255 so pixel values range [0,1], swap colour channels, resize)\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)  # sets the blob as the input of the network\n",
    "    outs = net.forward(output_layers) # feed forward (inference) and get the network output\n",
    "\n",
    "    # Showing information on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs: # loop over each of the layer outputs\n",
    "        for detection in out: # loop over each of the object detection \n",
    "            # extract the label/class id and confidence (as a probability) of the current object detection \n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.3: # discard weak predictions by ensuring detected prob > min. prob which is set at 0.3 in this case\n",
    "                # note that YOLO returns the centre (x,y) coordinates of the bounding box followed by the box's width and height\n",
    "                # print('class_id:', class_id)\n",
    "                #scaling the bounding box coordinates back relative to the size of the image\n",
    "                center_x = int(detection[0] * width) \n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # deriving bottom and left corner coordinates of bounding box\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # update list of bounding box coordinates, confidences, and class ids\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # perform non maximum suppression -> to select the most appropriate bounding box for the object\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    predicted_y.append(len(indexes)) # len(indexes) = 0 means no valid detection, len(indexes)>=1 means got valid detection\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)): # drawing rectangles on images with valid bounding box, i.e. confidence>0.3\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[class_ids[i]]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2) # draw a rectangle on the image\n",
    "            cv2.putText(img, label, (x, y + 30), font, 1, color, 2) # put label text on the image\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    key = cv2.waitKey(1) # waitKey(1) will play the images continuously, while waitKey(0) will play still images that change upon pressing any key\n",
    "\n",
    "cv2.destroyAllWindows() # close the window once all images finish displaying\n",
    "print('predicted results: ',predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d219fc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrix for results of testing yolov3_training_final.weights on yolo_test_images_final\n",
    "\n",
    "false_negative = 0 # create counters for each of the 4 scenarios: FP,FN,TP,TN\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "true_positive = 0\n",
    "\n",
    "for i in range(len(actual_y)):\n",
    "    if actual_y[i]>=1 and predicted_y[i]>=1:# if actual y is 1 and predicted y is 1 => true positive\n",
    "        true_positive+=1\n",
    "    elif actual_y[i]>=1 and predicted_y[i]==0: # if actual y is 1 and predicted y is 0 => false negative\n",
    "        false_negative+=1\n",
    "    elif actual_y[i]==0 and predicted_y[i]==0: # if actual y is 0 and predicted y is 0 => true negative\n",
    "        true_negative+=1\n",
    "    elif actual_y[i]==0 and predicted_y[i]>=1: # if actual y is 0 and predicted y is 1 => false positive\n",
    "        false_positive+=1\n",
    "\n",
    "conf_arr = [[false_negative,true_positive], # this is the structure of the confusion matrix: FN at top left, FP at bottom right\n",
    "            [true_negative,false_positive] \n",
    "            ]\n",
    "\n",
    "norm_conf = []\n",
    "for i in conf_arr:\n",
    "    a = 0\n",
    "    tmp_arr = []\n",
    "    a = sum(i, 0)     # sum up the counts in each row, eg. FN + TP => this represents the total actual positive images\n",
    "    for j in i:\n",
    "        tmp_arr.append(float(j)/float(a)) # calculate the ratio \n",
    "    norm_conf.append(tmp_arr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.clf() # clear previous figure (if any) to make way for new figure\n",
    "fig.suptitle('Confusion Matrix Final', fontsize=20)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
    "                interpolation='nearest')\n",
    "\n",
    "width, height = np.array(conf_arr).shape\n",
    "\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        ax.annotate(str(conf_arr[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "\n",
    "cb = fig.colorbar(res)\n",
    "x_axis_label = ['Predicted 0 (no box)','Predicted 1 (got box)']\n",
    "y_axis_label = ['Actual 1 (got box)','Actual 0 (no box)']\n",
    "plt.xticks(range(width), x_axis_label[:width])\n",
    "plt.yticks(range(height), y_axis_label[:height])\n",
    "plt.savefig('confusion_matrix_final.png', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aed257",
   "metadata": {},
   "source": [
    "##### Results of Testing\n",
    "From the first row of the confusion matrix shown above, it can be seen that out of 25 images with carton boxes in it, the model was able to detect/predict the carton box in 22 of those images. This gives us a <b>true positive rate</b> of <u>22/25 = 88%</u>. There were 3 images which contained carton boxes but the model wrongly predicted that there were no carton boxes in them. This gives us a <b>false negative rate</b> of <u>3/25 = 12%</u>. <br><br>\n",
    "From the second row, it can be seen that out of 25 images without carton boxes in it, the model correctly predicted/detected that there were no carton boxes for 21 of them. This gives us a <b>true negative rate</b> of <u>21/25 = 84%</u>. There were 4 images which did not contain carton boxes but the model wrongly predicted that there were carton boxes in them. This gives us a <b>false positive rate</b> of <u>4/25 = 16%</u>.<br><br>\n",
    "Hence, the <b>overall accuracy rate</b> is <u>(21+22)/50 = 86%</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17d9c333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save location of confusion matrix image: \n",
      "C:\\Users\\LeeX\\Desktop\\Proof_Of_Concept\\2c_train_yolo_to_clean_scraped_images\\yolo_custom_detection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\LeeX\\\\Desktop\\\\Proof_Of_Concept\\\\'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Save location of confusion matrix image: ')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# setting up directory for removing irrelevant scraped images in the next step\n",
    "index_position = cwd.find('Proof_Of_Concept\\\\') + len('Proof_Of_Concept\\\\')\n",
    "cwd = cwd[:index_position] \n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e4650",
   "metadata": {},
   "source": [
    "## Applying Yolov3 model to clean webscraped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc4b2aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of irrelevant images removed:  633\n"
     ]
    }
   ],
   "source": [
    "# applying the model by running it through the folders containing webscraped images\n",
    "\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3_training_final.weights\", \"yolov3_testing.cfg\")\n",
    "\n",
    "# Name custom object\n",
    "classes = [\"carton_box\"]\n",
    "\n",
    "# Images path (will require some minor change in directory path)\n",
    "images_path_bad = glob.glob(r\"C:\\Users\\LeeX\\Desktop\\Proof_Of_Concept\\good_bad_carton_images\\webscraped_bad\\*.jpg\")\n",
    "images_path_good = glob.glob(r\"C:\\Users\\LeeX\\Desktop\\Proof_Of_Concept\\good_bad_carton_images\\webscraped_good\\*.jpg\")\n",
    "images_path_list = [images_path_bad, images_path_good]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "count = 0 # number of irrelevant images counter\n",
    "\n",
    "# Insert here the path of your images\n",
    "# random.shuffle(images_path)\n",
    "\n",
    "# loop through all the images\n",
    "for images_path in images_path_list:\n",
    "    for img_path in images_path:\n",
    "    # Loading image\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, None, fx=0.8, fy=0.8)\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "    # creating a 4D blob + preprocessing (normalising images by rescaling 1/255 so pixel values range [0,1], swap colour channels, resize)\n",
    "        blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "        net.setInput(blob)  # sets the blob as the input of the network\n",
    "        outs = net.forward(output_layers) # feed forward (inference) and get the network output\n",
    "\n",
    "    # Showing information on the screen\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        for out in outs: # loop over each of the layer outputs\n",
    "            for detection in out: # loop over each of the object detection \n",
    "            # extract the label/class id and confidence (as a probability) of the current object detection \n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.3: # discard weak predictions by ensuring detected prob > min. prob which is set at 0.3 in this case\n",
    "                # note that YOLO returns the centre (x,y) coordinates of the bounding box followed by the box's width and height\n",
    "                # print('class_id:', class_id)\n",
    "                #scaling the bounding box coordinates back relative to the size of the image\n",
    "                    center_x = int(detection[0] * width) \n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                # deriving bottom and left corner coordinates of bounding box\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                # update list of bounding box coordinates, confidences, and class ids\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # perform non maximum suppression -> to select the most appropriate bounding box for the object\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        if len(indexes)==0:\n",
    "            os.remove(img_path)\n",
    "            count += 1   \n",
    "\n",
    "print('No. of irrelevant images removed: ',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150590d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c739b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
