{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d92a429",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d723619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test split & create new directories for train test split\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "# convert train images to array\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# train validation split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b6e46f",
   "metadata": {},
   "source": [
    "1. To execute SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "'sm = SMOTE(random_state=42)\n",
    "'X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "'model.fit(X_smote, y_smote)'\n",
    "=> X_train and y_train need to be in array form, hence need convert image data into array data\n",
    "\n",
    "Step 1: split into train and test dataset first\n",
    "Step 2: convert train image data into array data\n",
    "Step 3: execute SMOTE\n",
    "Step 4: train model with SMOTEd inputs + imagedatagenerator augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1a659",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "162832c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test split & create new directories for train test split\n",
    "\n",
    "seed(1) # seed random number generator\n",
    "val_ratio = .20 # set ratio of pictures to use for validation\n",
    "\n",
    "newdir = 'train_test_dataset/'\n",
    "subdirs = ['train/','test/']\n",
    "for sub in subdirs:\n",
    "    labeldirs=['good/','bad/']\n",
    "    for labeldir in labeldirs:\n",
    "        os.makedirs(newdir + sub + labeldir, exist_ok=True)\n",
    "copy_from_dir = 'good_bad_carton_images/'\n",
    "copy_from_folders_list = os.listdir(copy_from_dir) #['internal_bad','internal_good','webscraped_bad','webscraped_good']\n",
    "\n",
    "for folder in copy_from_folders_list:\n",
    "    copy_from_folder = copy_from_dir + folder\n",
    "    for file in os.listdir(copy_from_folder):\n",
    "        src = copy_from_folder + '/' + file\n",
    "        dst_dir = 'train/'\n",
    "        if random() < val_ratio:\n",
    "            dst_dir = 'test/'\n",
    "        if folder in ['internal_bad','webscraped_bad']:\n",
    "            dst = newdir + dst_dir + 'bad/' + file\n",
    "        else:\n",
    "            dst = newdir + dst_dir + 'good/' + file\n",
    "        copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c559f455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test images: 438\n",
      "# of train images: 1810\n",
      "actual test ratio:  0.2419889502762431\n"
     ]
    }
   ],
   "source": [
    "# check train test split\n",
    "num_test_img = len(os.listdir('train_test_dataset/test/good')) + len(os.listdir('train_test_dataset/test/bad'))\n",
    "num_train_img = len(os.listdir('train_test_dataset/train/good')) + len(os.listdir('train_test_dataset/train/bad'))\n",
    "print('# of test images:', num_test_img)\n",
    "print('# of train images:', num_train_img)\n",
    "print('actual test ratio: ', num_test_img/num_train_img)\n",
    "\n",
    "# 24.2% of images (438) are put away for testing the model after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19283669",
   "metadata": {},
   "source": [
    "## Resizing and converting images to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "11a81a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize train images to 224x224 (size required for VGG16) and convert train images to numpy array\n",
    "\n",
    "images, labels = list(), list()\n",
    "train_dir = 'train_test_dataset/train/'  \n",
    "train_subdirs = os.listdir(train_dir) # ['bad', 'good']\n",
    "for subdir in train_subdirs:\n",
    "    # determine class, 0 is bad, 1 is good\n",
    "    output=0\n",
    "    if subdir == 'good':\n",
    "        output=1\n",
    "    # enumerate images in each subdir\n",
    "    for file in os.listdir(train_dir + subdir):\n",
    "        # load image\n",
    "        image = load_img(train_dir + subdir + '/' + file, target_size=(224,224))\n",
    "        # convert to numpy array\n",
    "        image = img_to_array(image)\n",
    "        # store\n",
    "        images.append(image)\n",
    "        labels.append(output)\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0dbaef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1810, 224, 224, 3)\n",
      "[1095  715]\n"
     ]
    }
   ],
   "source": [
    "# check shape and class count before SMOTE\n",
    "\n",
    "print(X_train.shape)\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a828b",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d44bcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to reshape X_train from shape (a,b,c,d) into (a,b) for SMOTE\n",
    "X_train = X_train.reshape(1810, 224*224*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "acbd5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing SMOTE; res stands for resampled - to denote training dataset balanced by SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b93f4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2190, 150528)\n",
      "[1095 1095]\n"
     ]
    }
   ],
   "source": [
    "# check shape and class count after SMOTE\n",
    "# note that the class count is now balanced; this means SMOTE oversampling is successful\n",
    "print(X_res.shape)\n",
    "print(np.bincount(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2375e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape back from (a,b) to (a,b,c,d)\n",
    "X_res = X_res.reshape(2190, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86a6ce",
   "metadata": {},
   "source": [
    "## Further splitting train set into train-validation test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c197f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-validation split for train and validation sets\n",
    "#15/85 split with random state of 32\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_res, y_res, random_state=32, test_size = 0.15, stratify=y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fc17762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1861, 224, 224, 3)\n",
      "y_train:  (1861,)\n",
      "X_val:  (329, 224, 224, 3)\n",
      "y_val:  (329,)\n",
      "[931 930]\n",
      "[164 165]\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ', X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('X_val: ', X_val.shape)\n",
    "print('y_val: ', y_val.shape)\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "032a06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export train validation data\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('y_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "51c7a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "np.save('X_res.npy', X_res)\n",
    "np.save('y_res.npy', y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525032f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
